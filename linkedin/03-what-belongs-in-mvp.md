---
title: "Most MVPs fail because founders build too much. Here's what actually needs to be in a minimum viable product."
date: 2025-01-15
draft: false
---

Most MVPs fail because founders build too much.

I've built MVPs for about thirty different startups over the past decade. The successful ones shared a common trait: ruthless focus on answering one specific question.

The failed ones tried to answer many questions at once. They built beautiful interfaces, complete feature sets, polished experiences. They took months. By launch, the assumptions they were testing had already changed.

A founder came to me last year with a forty-page spec for an AI sales tool. Budget: €60k. Timeline: four months.

I asked: "What's the one thing you need to learn?"

He said: "I need to know if sales teams will actually use AI-generated emails, or ignore them like every other tool."

"What's the absolute minimum you could build to learn that?"

We spent two hours cutting. We ended up with: a web form where you paste a LinkedIn profile, a button that generates an email draft, a way to copy the result. No authentication, no billing, no dashboard.

We built it in a week. Cost: €5k.

He sent it to twenty sales people. Fifteen used it. Ten asked to keep using it. Three offered to pay.

That's when we knew we had something. Then we spent months building the real product—knowing exactly what mattered.

There's confusion around MVPs. "Minimum" isn't a compromise. It's about building precisely what's needed to learn what you need to learn, and nothing more.

"Viable" doesn't mean feature complete or polished. It means viable for learning. Can this teach you what you need to know?

I start with: what question is this MVP meant to answer? Usually it's one of three things: will people use this, can we build this, or will people pay for this.

Most MVPs try to answer all three. That's a mistake. Pick one. Build the minimum thing that answers it. Then iterate.

Features that don't belong in MVPs: user authentication (use a simple password), admin dashboards (look at the database), perfect error handling (you'll be watching anyway), beautiful UI (good enough is fine), analytics (you'll have ten users—email them), scalability (fix performance when you have evidence people want this).

Here's my heuristic: if you can't build and deploy your MVP in two weeks, you're building too much. Not two weeks of planning—two weeks from deciding to build it to having it in front of users.

This forces brutal prioritization. You can't build authentication and billing and analytics in two weeks. You can build one valuable thing.

When someone hires me to build an MVP, the first thing I do is cut scope. Usually by half. This is the most valuable part, and it happens before I write code.

I ask uncomfortable questions: "Do you really need this? What if we just didn't build it? Can we test this differently?"

Most founders have never had someone push back on scope. Developers estimate whatever's in the spec. Agencies love big scopes. The incentive is to build more.

I have the opposite incentive. I want to build the minimum thing that actually teaches you something. Over-built MVPs sit unused while founders "fix product-market fit." Under-built MVPs get used, provide feedback, and evolve into real products.

I help founders build MVPs in two to three weeks. Not because I code faster, but because I'm good at cutting scope to the essential core.

The hardest part isn't the coding. It's deciding what not to build.

---

Need help scoping your MVP? https://calendly.com/nasir-fio/30min
